# Visualization Scripts
We provide various visualization functionlaities on TAO-Amodal, including:
<ul>
    <li>
      <a href="#visualize-mask-and-amodal-bounding-box">Visualize Modal Mask & Amodal Box</a>
    </li>
    <li>
      <a href="#visualize-tracker-prediction">Visualize Tracker Predictions</a>
    </li>
    <li>
      <a href="#parameter-definition">Parameter Definitions</a>
    </li>
</ul>


# Usage
#### [Visualize mask and amodal bounding box](https://tao-amodal.github.io/dataset.html)

1. Randomly visualize 5 videos from each subset in TAO-Amodal training set. Videos will be saved in ```output-dir```.
```bash
# Modify --mask-annotations, --annotations, --output-dir, --images-dir
python ./vis_amodal_mask_videos_webpage.py \
    --mask-annotations /path/to/BURST_annotations/train/train_visibility.json \
    --annotations /path/to/amodal_annotations/train.json \
    --output-dir /path/to/output_dir \
    --images-dir /path/to/TAO-Amodal/frames \
    --split train \
    --slow-down 25 \
    --speed-up -1 \
    --random-quality-check True \
    --random-quality-check-size 5
```
* Example output

| Modal | Amodal |
|---|---|
|<div align="center"><a href="https://tao-amodal.github.io/static/videos/cattle-7_both.mp4"><img width="95%" alt="TAO-Amodal" src="https://tao-amodal.github.io/static/images/webpage_preview.png"></a></div> | <div align="center"><a href="https://tao-amodal.github.io/static/videos/cattle-7_both.mp4"><img width="95%" alt="TAO-Amodal" src="https://tao-amodal.github.io/static/images/webpage_preview.png"></a></div>|

> More examples could be found [here](https://tao-amodal.github.io/dataset.html).

---
2. Visualize a specified track with a certain color
```bash
# Visualize amodal boxes
python ./vis_amodal_mask_videos_webpage.py \
    --mask-annotations /path/to/TAO/BURST_annotations/val/all_classes_visibility.json \
    --annotations /path/to/TAO/amodal_annotations/validation.json \
    --output-dir /path/to/output-dir \
    --images-dir /path/to/TAO/frames \
    --slow-down 15 \
    --speed-up 2 \
    --split val \
    --show-categories False \
    --transparent True \
    --filter-tracks 14226 \
    --interpolate True \
    --video-name val/LaSOT/cattle-7

# Visualize modal boxes
python ./vis_amodal_mask_videos_webpage.py \
    --mask-annotations /path/to/TAO/BURST_annotations/val/all_classes_visibility.json \
    --annotations /path/to/TAO/amodal_annotations/validation.json \
    --output-dir /path/to/output-dir \
    --images-dir /path/to/TAO/frames \
    --slow-down 15 \
    --speed-up 2 \
    --split val \
    --show-categories False \
    --transparent True \
    --filter-tracks 14226 \
    --interpolate True \
    --video-name val/LaSOT/cattle-7 \
    --modal True
```

* Example output:

| Modal | Amodal |
|---|---|
|<div align="center"><a href="https://tao-amodal.github.io/static/videos/cattle-7_both.mp4"><img width="95%" alt="TAO-Amodal" src="https://tao-amodal.github.io/static/images/webpage_preview.png"></a></div> | <div align="center"><a href="https://tao-amodal.github.io/static/videos/cattle-7_both.mp4"><img width="95%" alt="TAO-Amodal" src="https://tao-amodal.github.io/static/images/webpage_preview.png"></a></div>|

#### [Visualize Tracker Prediction](https://tao-amodal.github.io/#Amodal-Expander)
1. Visualize Prediction from One Tracker
The prediction JSON should be structured following [this format](https://huggingface.co/datasets/chengyenhsieh/TAO-Amodal#annotation-and-prediction-format). Example prediction JSON file generated by our Amodal Expander could be found [here](https://huggingface.co/datasets/chengyenhsieh/TAO-Amodal/tree/main/example_output).

```bash
# Show specified track with a certain color
python ./vis_amodal_prediction_comparison.py \
    --annotations /path/to/TAO/amodal_annotations/validation_lvis_v1.json \
    --predictions /path/to/prediction.json \
    --output-dir /path/to/output-dir \
    --images-dir /path/to/TAO-Amodal/frames \
    --split val \
    --slow-down 15 \
    --speed-up 1 \
    --transparent True \
    --filter-tracks 120002060002 \
    --color 255 244 146 \
    --video-name val/ArgoVerse/side_left_043aeba7-14e5-3cde-8a5c-639389b6d3a6
```
```bash
# Visualize all tracks from randomly picked videos
python ./vis_amodal_prediction_comparison.py \
    --annotations /path/to/TAO/amodal_annotations/validation_lvis_v1.json \
    --predictions /path/to/prediction.json \
    --split val \
    --output-dir /path/to/output-dir \
    --images-dir /path/to/TAO-Amodal/frames \
    --slow-down 15 \
    --speed-up 1 \
    --random-quality-check True \
    --random-quality-check-size 10
```

2. Compare Tracker Predictions
Run the following command to compare predictions from two trackers. For example, you can compare the [modal](https://huggingface.co/datasets/chengyenhsieh/TAO-Amodal/blob/main/example_output/modal_prediction.json) and [amodal](https://huggingface.co/datasets/chengyenhsieh/TAO-Amodal/blob/main/example_output/prediction.json) predictions generated by our Amodal Expander.

```bash
# Show specified track with a certain color
python ./vis_amodal_prediction_comparison.py \
    --annotations /path/to/TAO/amodal_annotations/validation_lvis_v1.json \
    --predictions /path/to/modal_prediction.json \
    --predictions2 /path/to/prediction.json \
    --output-dir /path/to/output-dir \
    --images-dir /path/to/TAO-Amodal/frames \
    --split val \
    --slow-down 15 \
    --speed-up 1 \
    --transparent True \
    --filter-tracks 120002060002 \
    --color 255 244 146 \
    --video-name val/ArgoVerse/side_left_043aeba7-14e5-3cde-8a5c-639389b6d3a6
```
```bash
# Visualize all tracks from randomly 5*7=35 picked videos
python ./vis_amodal_prediction_comparison.py \
    --annotations /path/to/TAO/amodal_annotations/validation_lvis_v1.json \
    --predictions /path/to/modal_prediction.json \
    --predictions2 /path/to/prediction.json \
    --split val \
    --output-dir /path/to/output-dir \
    --images-dir /path/to/TAO-Amodal/frames \
    --slow-down 15 \
    --speed-up 1 \
    --random-quality-check True \
    --random-quality-check-size 5
```

#### Parameter Definition
We provide different parameters for better customization (e.g., bounding box/video) of your visualization results. For example, you can do interpolation, specify colors or making the background transparent to emphasize the bounding boxes.

Check [utils.py](./utils.py#L16) for the definition of each parameter.